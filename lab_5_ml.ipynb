{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPndaI3Vw5KAoviGYE90LEj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guljeren/Ml_lab/blob/main/lab_5_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcbkoklSHNWX",
        "outputId": "f1c00099-dbf2-474f-d2e9-d8b40b02cc51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найдено новостей на странице: 20\n",
            "Успешно собрано: 20 новостей\n",
            "\n",
            " Предобработка текстов:\n",
            "Пример очистки:\n",
            "До:   Российские бойцы зашли в тылВооруженных силУкраины(ВСУ) в боях за Красноармейск ...\n",
            "После: российские бойцы зашли в тылвооруженных силукраины всу в боях за красноармейск и...\n",
            "\n",
            "Создание частотного словаря...\n",
            "Всего уникальных слов: 1725\n",
            "Топ-10 самых частых слов:\n",
            "  что: 58\n",
            "  для: 14\n",
            "  она: 14\n",
            "  его: 13\n",
            "  этом: 12\n",
            "  это: 11\n",
            "  ранее: 11\n",
            "  всу: 10\n",
            "  также: 10\n",
            "  как: 10\n",
            "Размер BoW матрицы: (20, 1000)\n",
            "Количество признаков (слов): 1000\n",
            "Размер матрицы эмбеддингов: (1000, 50)\n",
            "РЕЗУЛЬТАТЫ\n",
            "\n",
            " news_50_processed.csv\n",
            "   - 20 новостей\n",
            "   - Колонки: ['title', 'text', 'link', 'cleaned_text']\n",
            "\n",
            " bow_matrix.csv\n",
            "   - Размер: (20, 1000)\n",
            "   - Формат: CSV (можно открыть в Excel)\n",
            "\n",
            " embedding_matrix.npy\n",
            "   - Размер: (1000, 50)\n",
            "   - Формат: NumPy binary\n",
            "\n",
            " word_frequency.csv\n",
            "   - 1725 уникальных слов\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# ПАРСИНГ 50 НОВОСТИ\n",
        "def parse_lenta_news(num_news=50):\n",
        "    url = \"https://lenta.ru/parts/news/\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "    except:\n",
        "        print(\"Ошибка подключения к сайту\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    news_items = soup.find_all('a', class_='card-full-news _parts-news')\n",
        "\n",
        "    # Берем указанное количество новостей\n",
        "    available = min(len(news_items), num_news)\n",
        "    news_items = news_items[:available]\n",
        "\n",
        "    data = []\n",
        "    print(f\"Найдено новостей на странице: {len(news_items)}\")\n",
        "\n",
        "    for i, item in enumerate(news_items):\n",
        "        title = item.get_text(strip=True)\n",
        "        link = item.get('href')\n",
        "\n",
        "        if link and link.startswith('/'):\n",
        "            link = 'https://lenta.ru' + link\n",
        "\n",
        "        # Получаем текст новости\n",
        "        text_content = \"\"\n",
        "        if link and i < 20:  # Для первых 20 новостей получаем полный текст\n",
        "            try:\n",
        "                article_response = requests.get(link, headers=headers, timeout=5)\n",
        "                if article_response.status_code == 200:\n",
        "                    article_soup = BeautifulSoup(article_response.text, 'html.parser')\n",
        "                    text_block = article_soup.find('div', class_='topic-body__content')\n",
        "                    if text_block:\n",
        "                        paragraphs = text_block.find_all('p')\n",
        "                        text_content = ' '.join([p.get_text(strip=True) for p in paragraphs])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Если не удалось получить текст, используем заголовок\n",
        "        if not text_content or len(text_content) < 50:\n",
        "            text_content = title\n",
        "\n",
        "        data.append({\n",
        "            'title': title,\n",
        "            'text': text_content,\n",
        "            'link': link\n",
        "        })\n",
        "\n",
        "    return data\n",
        "\n",
        "#ПРЕДОБРАБОТКА ТЕКСТА\n",
        "def clean_text(text):\n",
        "    \"\"\"Очистка текста от знаков препинания и лишних символов\"\"\"\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # Удаляем всё, кроме букв и пробелов\n",
        "    text = re.sub(r'[^а-яёa-z\\s]', ' ', text)\n",
        "\n",
        "    # Удаляем лишние пробелы\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def main():\n",
        "    #Парсим 50 новостей\n",
        "    news_data = parse_lenta_news(50)\n",
        "\n",
        "    if not news_data:\n",
        "        print(\"Не удалось получить новости. Проверьте интернет-соединение.\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame(news_data)\n",
        "    print(f\"Успешно собрано: {len(df)} новостей\")\n",
        "\n",
        "    # Очистка текстов\n",
        "    print(\"\\n Предобработка текстов:\")\n",
        "    df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "    # Показываем пример\n",
        "    print(\"Пример очистки:\")\n",
        "    print(f\"До:   {df['text'].iloc[0][:80]}...\")\n",
        "    print(f\"После: {df['cleaned_text'].iloc[0][:80]}...\")\n",
        "\n",
        "    # 3. Создаем частотный словарь\n",
        "    print(\"\\nСоздание частотного словаря...\")\n",
        "    all_words = []\n",
        "    for text in df['cleaned_text']:\n",
        "        words = text.split()\n",
        "        all_words.extend([w for w in words if len(w) > 2])\n",
        "\n",
        "    from collections import Counter\n",
        "    word_freq = Counter(all_words)\n",
        "\n",
        "    print(f\"Всего уникальных слов: {len(word_freq)}\")\n",
        "    print(\"Топ-10 самых частых слов:\")\n",
        "    for word, count in word_freq.most_common(10):\n",
        "        print(f\"  {word}: {count}\")\n",
        "\n",
        "    # 4. Bag of Words с помощью CountVectorizer\n",
        "    vectorizer = CountVectorizer(max_features=1000, stop_words=['и', 'в', 'на', 'с', 'по', 'о', 'к', 'у', 'от', 'за'])\n",
        "    bow_matrix = vectorizer.fit_transform(df['cleaned_text'])\n",
        "\n",
        "    print(f\"Размер BoW матрицы: {bow_matrix.shape}\")\n",
        "    print(f\"Количество признаков (слов): {len(vectorizer.get_feature_names_out())}\")\n",
        "\n",
        "    # Сохраняем BoW в CSV\n",
        "    bow_df = pd.DataFrame(\n",
        "        bow_matrix.toarray(),\n",
        "        columns=vectorizer.get_feature_names_out()\n",
        "    )\n",
        "    bow_df.to_csv('bow_matrix.csv', index=False)\n",
        "\n",
        "    # 5. Создание матрицы эмбеддингов (простая версия)\n",
        "    vocab_size = len(vectorizer.vocabulary_)\n",
        "    embedding_dim = 50\n",
        "\n",
        "    # Создаем случайную матрицу эмбеддингов (в реальности нужно загружать предобученную)\n",
        "    embedding_matrix = np.random.randn(vocab_size, embedding_dim)\n",
        "\n",
        "    # Нормализуем векторы\n",
        "    embedding_matrix = embedding_matrix / np.linalg.norm(embedding_matrix, axis=1, keepdims=True)\n",
        "\n",
        "    print(f\"Размер матрицы эмбеддингов: {embedding_matrix.shape}\")\n",
        "\n",
        "    # Сохраняем матрицу эмбеддингов\n",
        "    np.save('embedding_matrix.npy', embedding_matrix)\n",
        "\n",
        "    # 6. Сохранение всех результатов\n",
        "    df.to_csv('news_50_processed.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "    # Сохраняем частотный словарь\n",
        "    freq_df = pd.DataFrame(list(word_freq.items()), columns=['word', 'count'])\n",
        "    freq_df.to_csv('word_frequency.csv', index=False)\n",
        "\n",
        "    # 7. Вывод итог\n",
        "    print(\"РЕЗУЛЬТАТЫ\")\n",
        "    print(\"\\n news_50_processed.csv\")\n",
        "    print(f\"   - {len(df)} новостей\")\n",
        "    print(f\"   - Колонки: {list(df.columns)}\")\n",
        "\n",
        "    print(\"\\n bow_matrix.csv\")\n",
        "    print(f\"   - Размер: {bow_matrix.shape}\")\n",
        "    print(f\"   - Формат: CSV (можно открыть в Excel)\")\n",
        "\n",
        "    print(\"\\n embedding_matrix.npy\")\n",
        "    print(f\"   - Размер: {embedding_matrix.shape}\")\n",
        "    print(f\"   - Формат: NumPy binary\")\n",
        "\n",
        "    print(\"\\n word_frequency.csv\")\n",
        "    print(f\"   - {len(word_freq)} уникальных слов\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}